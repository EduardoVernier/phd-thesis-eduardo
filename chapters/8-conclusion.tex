\chapter{Conclusion}


% -we examined the evaluation and improvement of viz algos for abstract dynamic data.
% -we considered 2 main instances of this data: hierarchies and high-dim datasets.
% -in both cases, we found out that quality can be described by two main criteria: vis quality and stability
% -in both cases, for vis quality, we could reuse existing metrics from vizzes for static data of those types
% -in both cases, for stability, there was nothing; we could propose new metrics for that, which are interestingly almost the SAME for the 2 kinds of data; they basically measure the DERIVATIVE of the visualization function (how much the vis changes when the data changes that much)
% -in both cases, we found that the 2 qual criteria are multually competing; also, we did benchmarks, and found thereâ€™s no clear winner in the existing algos; some optimize vis qual but thrash stability, some the other way round, some are kind of in the middle
% -in both cases, we proposed improvements to existing algos which overall increased BOTH qual metrics (vis qual, stability)

% Then, of course, you can add something in this section concerning

% -limitations: feel free to say what could have been done better ðŸ˜Š
% -future work: feel free to speculate here too ðŸ˜Š
% [I can of course suggest a lot here, but I donâ€™t want to monopolize the writing]

% Anyways, the conclusion should be like 3-4 pages, not more.

In this thesis, we considered the visualization of two types of dynamic (time-dependent) data present in information visualization -- weighted hierarchies and high-dimensional datasets. Both data types are ubiquitous in many applications in machine learning, statistics, and data science; and, as identified at the beginning of the thesis, while many techniques have been proposed for the visualization of static (time-independent) forms of both data types, the investigation of techniques that handle the dynamic variants has only been touched in information visualization.

Throughout our work, we found interesting and insightful parallels between the two types of datasets, the challenges they pose to visualization and the visualization evaluation, and also the solutions that we designed to handle both.

Chapter~\ref{ch:soft-eval} kickstarted our work by considering treemap algorithms for the visualization of a particular type of data, namely hierarchies mined from evolving software projects. Already in this limited context, we found that quality of a treemapping algorithm contains two components, namely \emph{visual quality}, that captures how well the cells of the treemap are spread over the drawing space to reflect the data values and also generate easily readable patterns; and \emph{stability}, that measures how well the changes in the depicted treemaps follow the changes in the underlying hierarchies. We also found that the two quality aspects are, roughly speaking, in competition with each other: Algorithms that obtain a high visual quality do this by neglecting stability; and very stable algorithms yield a poor visual quality.

For both hierarchies and high-dimensional projections, we found well-established metrics for gauging visual quality in the literature, \emph{i.e.}, when time is not taken into consideration and only the quality of individual layouts is measured. For treemaps, the quality of the layout is well quantified by the aspect ratio of the contained cells, considering that cells closer to squares form a more readable visualization; for projections, visual quality is measured by how well the distances and neighborhoods from the high-dimensional space are preserved by the low-dimensional embedding.

Regarding stability, however, there were no effective methods of quantifying the relationship between \emph{data change} and \emph{visual change}. As such, and recognizing that stability is an as important desirable property for dynamic visualization as their (static) visual quality, we proposed our own stability metrics. Concerning dynamic treemaps, an algorithm is stable if small changes in the input data result in small changes in the layout, that is, data change and layout change correlate positively. Previously proposed stability metrics measured only the layout change and concluded that small layout changes are a sign of a stable algorithm. However, to properly measure stability, we also need to capture the data change and then correlate data and layout change, an endeavor which we approached in Chapters \ref{ch:soft-eval} and \ref{ch:tree-eval}. This exact same principle applies to dynamic projections. However, in this case, we correlate high-dimensional data change to low-dimensional scatterplot layout change (Chapter \ref{ch:proj-eval}).  

As already mentioned, we found out that visual quality and stability are conflicting criteria, both for treemaps and projections. In order to improve stability, both treemapping and dimensionality reduction methods have to sacrifice visual quality, and conversely. Recognizing this challenge, we next aimed to create methods that improve this balance -- that is, yield overall higher stability and visual quality than existing methods in each class. For dynamic hierarchies, we proposed to this end Greedy Insertion Treemaps (Chapter \ref{ch:git}). For multidimensional projections, we proposed the LD-tSNE and PCD-tSNE methods (Chapter \ref{ch:proj-algo}). Greedy Insertion Treemap (or GIT) aims to preserve treemap-cell neighborhoods over time by constructing an initial so-called Layout Tree (LT), a data structure which is incrementally updated as the input tree data changes, so as to minimize undesired treemap-layout changes. Our state-aware GIT method is simple to implement, generic (handles any types of dynamic hierarchies), and fast (compared to the other state-of-the-art methods). For the dynamic projection challenge, both our newly proposed methods leverage the neighborhood-preservation ability of t-SNE for dynamic time-dependent data. LD-tSNE uses guidance in the form of landmarks, and PCD-tSNE uses information given by the Principal Components of the full temporal dataset. Our results show that PCD-tSNE scores a good balance between stability, neighborhood preservation, and distance preservation, making it one of the best suited general methods for dynamic projections, while LD-tSNE allows creating stable and customizable projections via landmarks selection and steering. 

Another common aspect concerning both dynamic hierarchies and dynamic high-dimensional datasets is the difficulty of \emph{evaluation}. This comprises multiple aspects. Besides the availability of suitable quality metrics -- which we solved as described above -- there is also the difficulty of finding good collections of datasets on which to evaluate existing visualization methods. Such so-called benchmarks were introduced -- only very recently -- for static projections. However, no comprehensive benchmarks existed, at the time of writing this thesis, for static treemapping, let alone for dynamic treemapping and dynamic projections. We created and evaluated several such benchmarks, starting with one for dynamic hierarchies obtained from software evolution (Chapter~\ref{ch:soft-eval}), which we extended next to a far more general benchmark for dynamic hierarchies mined from a wide spectrum of application domains (Chapter~\ref{ch:tree-eval}), and ending with a benchmark for dynamic projections (Chapter~\ref{ch:proj-eval}). 
Creating these benchmarks posed both conceptual problems, in terms of how to describe the huge variability of dynamic datasets along a set of independent traits, and next how to sample these traits; but also practical problems, in terms of how to find real-world datasets that sample the universe of these dynamic datasets, and providing actual reference implementations for the tens of algorithms for treemapping and projection that we need to evaluate. While our proposed benchmarks are, definitely, not fully covering the space of possibilities, they are the first in the dynamic treemapping and projection arenas. We made them fully open source (datasets, algorithms, visualization techniques, quality metrics, and obtained results). We argue that these are important resources for the visualization community which can, now, easily compare new and existing algorithms with new and existing datasets for both practical and research-oriented goals.

\alex{I expanded and restructured a bit the above text.}

\eduardo{possible application text goes here}

\section{Limitations and future work}
